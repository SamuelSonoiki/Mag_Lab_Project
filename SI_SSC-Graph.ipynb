{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eef5a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#'MeanGradient', 'MaxPoint', 'DistRatio', 'PreviousChange','MeanGOther', 'PChangeOther', 'MaxPointOther', 'DistRatOther'\n",
    "PreX_train = [pd.read_csv(\"ML2014.csv\"), pd.read_csv(\"ML2016.csv\"), pd.read_csv(\"ML2015.csv\"), \n",
    "              pd.read_csv(\"ML2018.csv\"), pd.read_csv(\"ML2019.csv\")]\n",
    "PreX_test = pd.read_csv(\"ML2017.csv\")\n",
    "\n",
    "X_test = PreX_test.dropna()\n",
    "y_test = X_test['Type'].replace(2, 1, regex=True)\n",
    "X_test = X_test[['MeanGradient','MaxPoint',     'PreviousChange','DistRatio',\n",
    "                 'MeanGOther',  'MaxPointOther','PChangeOther',  'DistRatOther']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "079ebc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanGOther :  0.7219861206462571\n",
      "PChangeOther :  0.15511917261267122\n",
      "PreviousChange :  0.03612527223559169\n",
      "MeanGradient :  0.02847456188341243\n",
      "DistRatOther :  0.020780621002728393\n",
      "DistRatio :  0.018114847312723236\n",
      "MaxPointOther :  0.01321927186014093\n",
      "MaxPoint :  0.006180132446474817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from  sklearn.preprocessing import *\n",
    "from sklearn.linear_model import*\n",
    "\n",
    "# Round to the nearest number function\n",
    "def myround(x, base):\n",
    "    return base * round(x/base)\n",
    "\n",
    "importance = np.array([0, 0, 0, 0, 0, 0, 0, 0]) #Importance of features in decision tree\n",
    "index_sc = set()\n",
    "sc_year = {}\n",
    "main_sc = {}\n",
    "value = 1\n",
    "\n",
    "for data in PreX_train:\n",
    "    X_train = data.dropna()\n",
    "    y_train = X_train['Type'].replace(2, 1, regex=True)\n",
    "    X_train = X_train[['MeanGradient','MaxPoint',     'PreviousChange','DistRatio',\n",
    "                       'MeanGOther',  'MaxPointOther','PChangeOther',  'DistRatOther']]\n",
    "    \n",
    "    for number in range(0, 10):\n",
    "        \n",
    "        #Run Decision Tree \n",
    "        clfD = DecisionTreeClassifier(class_weight = {1: 20}, max_depth=70).fit(X_train, y_train)        \n",
    "        importance = importance + clfD.feature_importances_        \n",
    "        l = clfD.predict(X_test)\n",
    "        temp = X_test[l==value].index\n",
    "        \n",
    "        #Add all time indexes rounded off into a set\n",
    "        index_sc.clear()\n",
    "        for time_index in temp:        \n",
    "            index_sc.add(myround(time_index, 60))        \n",
    "        \n",
    "        #Increment dictionary value if time is predicted as a SC\n",
    "        for time_index in index_sc:\n",
    "            sc_year[time_index] = sc_year.get(time_index, 0) + 1\n",
    "            \n",
    "    #If time_index appears in all predictions for on year run add it to the main_sc dictionary\n",
    "    for time_index in sc_year:\n",
    "        if sc_year[time_index]==10:\n",
    "            main_sc[time_index] = main_sc.get(time_index, 0) + 1            \n",
    "            \n",
    "    sc_year.clear()\n",
    "\n",
    "# If time_index appears in one year ot more add it to the final prediction \n",
    "main = []\n",
    "for time_index in main_sc:\n",
    "    if main_sc[time_index]>=2:\n",
    "        main.append(time_index)\n",
    "        \n",
    "#List all features in order of importance\n",
    "importance = list(importance/50)\n",
    "ind = [importance.index(i) for i in sorted(importance, reverse=True)]\n",
    "for i in ind:\n",
    "    print(X_train.columns[i], ': ', importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b27fb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "[36480, 211200, 248880, 262740, 272160, 282600, 283440, 346620, 348840, 349920, 358560, 359940, 364320, 366960, 368700, 369300]\n",
      "16\n",
      "\n",
      "Actual:\n",
      "[36480, 159300, 178380, 193500, 211200, 232740, 263700, 272160, 282600, 348840, 358560, 359940, 366960, 369300, 422280]\n",
      "15\n",
      "\n",
      "Common:\n",
      "[36480, 211200, 272160, 282600, 348840, 358560, 359940, 366960, 369300]\n",
      "9\n",
      "\n",
      "Recall:  0.6\n",
      "Precision:  0.5625\n"
     ]
    }
   ],
   "source": [
    "#This shows the actual SC occurnces for a year and shows what my decision tree predicted.\n",
    "\n",
    "main = sorted(main)\n",
    "print(\"Predicted:\")\n",
    "print(main)\n",
    "print(len(main))\n",
    "print(\"\")\n",
    "\n",
    "temp = PreX_test[PreX_test[\"Type\"]>=1].dropna().index\n",
    "index_sc = set()\n",
    "index_sc.clear()\n",
    "for time_index in temp:        \n",
    "    index_sc.add(myround(time_index, 60))   \n",
    "    \n",
    "index_sc = sorted(index_sc)\n",
    "print(\"Actual:\")\n",
    "print(index_sc)\n",
    "print(len(index_sc))\n",
    "print(\"\")\n",
    "\n",
    "common_elements = list(set(index_sc) & set(main))\n",
    "print(\"Common:\")\n",
    "print(sorted(common_elements))\n",
    "print(len(common_elements))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Recall: \", len(common_elements) / len(index_sc))\n",
    "print(\"Precision: \", len(common_elements) / len(main))\n",
    "\n",
    "#PreX_test[(PreX_test[\"Type\"]>=1)].iloc[0:60].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd834f1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# suu = 156980\t                      \t                  \n",
    "# maxp = PreX_test[\"MaxPoint\"].iloc[suu]\n",
    "# width = 100\n",
    "# xpoints = np.array(PreX_test[\"DateTime\"].iloc[suu-width:suu+width+maxp])\n",
    "# ypoints = np.array(PreX_test[\"OtherH\"] .iloc[suu-width:suu+width+maxp])\n",
    "\n",
    "# plt.plot(xpoints, ypoints, label=\"OtherH\")\n",
    "\n",
    "# plt.plot(xpoints[width], ypoints[width], marker=\"o\", markersize=5)\n",
    "# plt.plot(xpoints[width+maxp], ypoints[width+maxp], marker=\"o\", markersize=5)\n",
    "# plt.xticks([0, width, width*2])\n",
    "# plt.yscale('linear')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# #xpoints1 = np.array(df[\"BzE\"].iloc[suu-width:suu+width+maxp].index)\n",
    "# #ypoints1 = np.array(df[\"BzE\"].iloc[suu-width:suu+width+maxp])\n",
    "# #xpoints2 = np.array(df[\"Pres\"].iloc[suu-width:suu+width+maxp].index)\n",
    "# #ypoints2 = np.array(df[\"Pres\"].iloc[suu-width:suu+width+maxp])\n",
    "# #plt.plot(xpoints1, ypoints1,  label=\"IMF BzE\")\n",
    "# #plt.plot(xpoints2, ypoints2,  label=\"Pressure\")\n",
    "# #plt.loglog(xpoints1[width], ypoints1[width], marker=\"o\", markersize=5)\n",
    "# #plt.loglog(xpoints2[width], ypoints2[width], marker=\"o\", markersize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d077310c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train = PreX_train[0]\n",
    "# X_train = X_train.dropna()\n",
    "# y_train = X_train['Type'].replace(2, 1, regex=True)\n",
    "# X_train = X_train[['MeanGradient', 'MaxPoint', 'PreviousChange',\n",
    "#                    'MeanGOther', 'PChangeOther', 'MaxPointOther', 'DistRatOther', 'DistRatio']]\n",
    "# X_test = pd.read_csv(\"ML2014.csv\")\n",
    "# X_test = X_test.dropna()\n",
    "# y_test = X_test['Type'].replace(2, 1, regex=True)\n",
    "# X_test = X_test[['MeanGradient', 'MaxPoint', 'PreviousChange',\n",
    "#                  'MeanGOther', 'PChangeOther', 'MaxPointOther', 'DistRatOther', 'DistRatio']]\n",
    "# importance = np.array([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "# for i in range(0,50):\n",
    "#     clfD = DecisionTreeClassifier(class_weight = 'balanced', max_depth=30).fit(X_train, y_train)\n",
    "#     importance = importance + clfD.feature_importances_\n",
    "# importance = list(importance/50)\n",
    "\n",
    "# ind = [importance.index(i) for i in sorted(importance, reverse=True)]\n",
    "# for i in ind:\n",
    "#     print(X_train.columns[i], ': ', importance[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070f3b5",
   "metadata": {},
   "source": [
    "PChangeOther :  0.37616510955881516\n",
    "MeanGOther :  0.20805968374414788\n",
    "dbn_nez :  0.11248257088661856\n",
    "PreviousChange :  0.11067556027145951\n",
    "MeanGradient :  0.09587584839792983\n",
    "MaxPointOther :  0.04873635582105554\n",
    "MaxPoint :  0.04800487131997364\n",
    "\n",
    "precision {'class_weight': {1: 20}, 'max_depth': 70}  {'class_weight': 'balanced', 'max_depth': 30}\n",
    "recall {'class_weight': 'balanced', 'max_depth': 10}\n",
    "\n",
    "BIG:\n",
    "class_weight = 'balanced', max_depth=30:\n",
    "MeanGOther :  0.9872417649205167\n",
    "MeanGradient :  0.006686358207849944\n",
    "PChangeOther :  0.003269756731754063\n",
    "PreviousChange :  0.001939027058299882\n",
    "MaxPointOther :  0.00044061760915292404\n",
    "dbn_nez :  0.00037961151778053424\n",
    "MaxPoint :  4.28639546459116e-05\n",
    "\n",
    "precision {'class_weight': 'balanced', 'max_depth': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0dd1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# X_train = PreX_train[0]\n",
    "# X_train = X_train.dropna()\n",
    "# y_train = X_train['Type'].replace(2, 1, regex=True)\n",
    "# X_train = X_train[['MeanGradient', 'MaxPoint', 'PreviousChange',\n",
    "#                    'MeanGOther', 'PChangeOther', 'MaxPointOther']]\n",
    "# X_test = pd.read_csv(\"ML2014.csv\")\n",
    "# X_test = PreX_test.dropna()\n",
    "# y_test = X_test['Type'].replace(2, 1, regex=True)\n",
    "# X_test = X_test[['MeanGradient', 'MaxPoint', 'PreviousChange',\n",
    "#                  'MeanGOther', 'PChangeOther', 'MaxPointOther']]\n",
    "\n",
    "# clf = DecisionTreeClassifier()\n",
    "# grid_params = {'class_weight':[None,'balanced',{1:2},{1:3},{1:4},{1:5},{1:10},{1:20},{1:50}],\n",
    "#                'max_depth':[None]+list(np.linspace(10, 100, 10, dtype = int))}\n",
    "# grid_ans = GridSearchCV(clf, param_grid = grid_params , scoring = 'precision')\n",
    "# grid_ans.fit(X_train, y_train)\n",
    "# y_scores = grid_ans.predict(X_test)\n",
    "# print(grid_ans.best_params_)\n",
    "# print(grid_ans.best_score_)    \n",
    "# print(recall_score(y_test, y_scores), \" \", precision_score(y_test, y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6cd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b02da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6b06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
