{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2597b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "df = pd.read_csv(\"Transformed/Comprehensive_SI_SSC_List.xlsx - Event_List.csv\")\n",
    "df = df.iloc[13:,1:5]\n",
    "df = df.rename(columns={\"Unnamed: 1\": \"Date\", \"Unnamed: 2\": \"Time\", \"Unnamed: 3\": \"DateTime\", \"Unnamed: 4\": \"Type\"})\n",
    "df[\"DateTime\"] = df[\"DateTime\"].apply(lambda x: str(x) + \":00\")\n",
    "df = df.replace(\"\", np.nan, regex=True);\n",
    "df = df.dropna()\n",
    "df[\"DateTime\"] = df[\"DateTime\"].apply(lambda x : pd.to_datetime(x))\n",
    "df = df.set_index(\"DateTime\").drop([\"Date\", \"Time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b323c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trans(transformed, filename):\n",
    "    now = datetime.datetime.now()\n",
    "    data = pd.read_csv(transformed)\n",
    "    X_train = data[['Type','dbn_nez']]\n",
    "    Ind = X_train[X_train[\"Type\"]!=0].index\n",
    "    change = X_train[\"dbn_nez\"].tolist()\n",
    "    change = change[1:] + [0]\n",
    "    change = change - X_train[\"dbn_nez\"]    \n",
    "    \n",
    "    arrCMean = []\n",
    "    arrPChange = []\n",
    "    arrPoint = []  \n",
    "    arrDD = []    \n",
    "    \n",
    "    for i in range(0, change.size):\n",
    "        arrCMean.append(change.iloc[i:i+5].mean())\n",
    "    X_train.insert(loc=2, column='MeanGradient', value=arrCMean)\n",
    "\n",
    "    for i in range(0, X_train['dbn_nez'].size):    \n",
    "        temp = X_train['MeanGradient'].iloc[i:i+20].abs() < 0.2\n",
    "        temp.iloc[-1] = True\n",
    "        temp = temp.tolist().index(True)\n",
    "        temp1 = X_train['MeanGradient'].iloc[i:i+20]\n",
    "        asign = np.sign(temp1)\n",
    "        temp1 = ((np.roll(asign, 1) - asign) != 0).astype(int)\n",
    "        temp1.iloc[0] = 0\n",
    "        temp1.iloc[-1] = 1\n",
    "        temp1 = temp1.tolist().index(1)\n",
    "        point = min(temp, temp1) + 1\n",
    "        arrPoint.append(point)  \n",
    "                     \n",
    "        if i+point >= X_train['dbn_nez'].size or i-(point*10)<0:\n",
    "            arrDD.append(np.nan)\n",
    "            arrPChange.append(np.nan) \n",
    "        else:\n",
    "            arrDD.append(change.iloc[i-(point*10):i].abs().mean() / (change.iloc[i+point:i+(point*11)].abs().mean()or.0001))       \n",
    "            temp  = X_train['MeanGradient'].iloc[i-(point*10):i-5]\n",
    "            arrPChange.append(temp.abs().max() / (X_train['MeanGradient'].iloc[i]or.0001))   \n",
    "            \n",
    "    X_train.insert(loc=5, column='MaxPoint', value=arrPoint)\n",
    "    X_train.insert(loc=6, column='DistRatio', value=arrDD)\n",
    "    X_train.insert(loc=7, column='PreviousChange', value=arrPChange)  \n",
    "    \n",
    "    for i in range(0, Ind.size):\n",
    "        typ = (X_train[\"Type\"].iloc[Ind[i]])\n",
    "        meanG = (X_train[\"MeanGradient\"].iloc[Ind[i]])\n",
    "        X_train[\"Type\"].iloc[Ind[i]-2] = typ * ((X_train[\"MeanGradient\"].iloc[Ind[i]-2] / meanG) > .6)\n",
    "        X_train[\"Type\"].iloc[Ind[i]-1] = typ * ((X_train[\"MeanGradient\"].iloc[Ind[i]-1] / meanG) > .6)\n",
    "        X_train[\"Type\"].iloc[Ind[i]+1] = typ * ((X_train[\"MeanGradient\"].iloc[Ind[i]+1] / meanG) > .6)\n",
    "        X_train[\"Type\"].iloc[Ind[i]+2] = typ * ((X_train[\"MeanGradient\"].iloc[Ind[i]+2] / meanG) > .6)\n",
    "    \n",
    "    X_train.to_csv(filename, encoding='utf-8', index = False)\n",
    "    timesince = (datetime.datetime.now()-now).total_seconds()\n",
    "    print(filename, \": \", int(timesince/60), \":\", int(timesince%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95798ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trans(\"2014Transformed.csv\", \"ML2014.csv\")\n",
    "#Trans(\"2015Transformed.csv\", \"ML2015.csv\")\n",
    "#Trans(\"2016Transformed.csv\", \"ML2016.csv\")\n",
    "#Trans(\"2017Transformed.csv\", \"ML2017.csv\")\n",
    "#Trans(\"2018Transformed.csv\", \"ML2018.csv\")\n",
    "#Trans(\"2019Transformed.csv\", \"ML2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransOther(txt, filename):\n",
    "    now = datetime.datetime.now()\n",
    "    Final = pd.read_csv(filename)\n",
    "    X_train = pd.read_fwf(txt)\n",
    "    change = X_train[\"SYM/H\"].tolist()\n",
    "    change = change[1:] + [0]\n",
    "    change = change - X_train[\"SYM/H\"]    \n",
    "    \n",
    "    arrCMean = []\n",
    "    arrPChange = []\n",
    "    arrPoint = []  \n",
    "    arrDD = []    \n",
    "    \n",
    "    for i in range(0, change.size):\n",
    "        arrCMean.append(change.iloc[i:i+5].mean())\n",
    "    Final[\"MeanGOther\"] = arrCMean\n",
    "\n",
    "    for i in range(0, Final[\"MeanGOther\"].size):    \n",
    "        temp = Final['MeanGOther'].iloc[i:i+20].abs() < 0.2\n",
    "        temp.iloc[-1] = True\n",
    "        temp = temp.tolist().index(True)\n",
    "        temp1 = Final['MeanGOther'].iloc[i:i+20]\n",
    "        asign = np.sign(temp1)\n",
    "        temp1 = ((np.roll(asign, 1) - asign) != 0).astype(int)\n",
    "        temp1.iloc[0] = 0\n",
    "        temp1.iloc[-1] = 1\n",
    "        temp1 = temp1.tolist().index(1)\n",
    "        point = min(temp, temp1) + 1\n",
    "        arrPoint.append(point)  \n",
    "                     \n",
    "        if i+point >= Final['MeanGOther'].size or i-(point*10)<0:\n",
    "            arrDD.append(np.nan)\n",
    "            arrPChange.append(np.nan) \n",
    "        else:\n",
    "            arrDD.append(change.iloc[i-(point*10):i].abs().mean() / (change.iloc[i+point:i+(point*11)].abs().mean()or.0001))       \n",
    "            temp  = Final['MeanGOther'].iloc[i-(point*10):i-5]\n",
    "            arrPChange.append(temp.abs().max() / (Final['MeanGOther'].iloc[i]or.0001))   \n",
    "            \n",
    "    Final[\"MaxPointOther\"] = arrPoint\n",
    "    Final[\"DistRatOther\"] = arrDD\n",
    "    Final[\"PChangeOther\"] = arrPChange  \n",
    "    \n",
    "    Final.to_csv(filename, encoding='utf-8', index = False)\n",
    "    timesince = (datetime.datetime.now()-now).total_seconds()\n",
    "    print(filename, \": \", int(timesince/60), \":\", int(timesince%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TransOther(\"2014.txt\", \"ML2014.csv\")\n",
    "#TransOther(\"2015.txt\", \"ML2015.csv\")\n",
    "#TransOther(\"2016.txt\", \"ML2016.csv\")\n",
    "#TransOther(\"2017.txt\", \"ML2017.csv\")\n",
    "#TransOther(\"2018.txt\", \"ML2018.csv\")\n",
    "#TransOther(\"2019.txt\", \"ML2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56b2f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransOther2(txt, filename, write):\n",
    "    Final = pd.read_csv(filename)\n",
    "    X_train = pd.read_fwf(txt)\n",
    "    Leg = pd.DataFrame(index=range(525600), columns=X_train.columns)\n",
    "\n",
    "    for i in range(0, X_train.size):    \n",
    "        Leg.iloc[i*60:(i*60)+60] = X_train.iloc[i:i+1]\n",
    "    Leg = Leg.drop(columns=['YEAR', 'DAY', 'H0'])    \n",
    "    Leg = pd.concat([Final, Leg], axis = 1)\n",
    "    Leg.to_csv(write, encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5046214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransOther2(\"2014.txt\", \"ML2014.csv\", \"NewML/ML2014.csv\")\n",
    "TransOther2(\"2015.txt\", \"ML2015.csv\", \"NewML/ML2015.csv\")\n",
    "TransOther2(\"2016.txt\", \"ML2016.csv\", \"NewML/ML2016.csv\")\n",
    "TransOther2(\"2017.txt\", \"ML2017.csv\", \"NewML/ML2017.csv\")\n",
    "TransOther2(\"2018.txt\", \"ML2018.csv\", \"NewML/ML2018.csv\")\n",
    "TransOther2(\"2019.txt\", \"ML2019.csv\", \"NewML/ML2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca136a08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def TransOther3(txt, filename, write):\n",
    "    Final = pd.read_csv(filename)\n",
    "    X_train = pd.read_fwf(txt)\n",
    "    X_train.columns = ['Year', 'Day', 'Hour', 'Min', 'BZE', 'BZM', 'Speed', 'Press','AE', 'AL']\n",
    "    X_train = X_train.drop(columns=['Year', 'Day', 'Hour', 'Min']) \n",
    "    X_train = X_train.replace([9999.99, 99999.9, 99.99, 99999] , np.nan) \n",
    "    X_train = X_train.fillna(method='ffill')\n",
    "    X_train = X_train.fillna(method='bfill')\n",
    "    X_train = pd.concat([Final, X_train], axis = 1)\n",
    "    X_train.to_csv(write, encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49c63747",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransOther3(\"2014.txt\", \"ML2014.csv\", \"NewML/ML2014.csv\")\n",
    "TransOther3(\"2015.txt\", \"ML2015.csv\", \"NewML/ML2015.csv\")\n",
    "TransOther3(\"2016.txt\", \"ML2016.csv\", \"NewML/ML2016.csv\")\n",
    "TransOther3(\"2017.txt\", \"ML2017.csv\", \"NewML/ML2017.csv\")\n",
    "TransOther3(\"2018.txt\", \"ML2018.csv\", \"NewML/ML2018.csv\")\n",
    "TransOther3(\"2019.txt\", \"ML2019.csv\", \"NewML/ML2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a505e112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv(\"NewML/ML2019.csv\")\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca5a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee73429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
